{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch16_part2_ryGenNovels_v02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoB8r9jr9a9rPlYam52C6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renyuanL/handwritten-digit-recognition/blob/master/ch16_part2_ryGenNovels_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOmGjRfPBqTj",
        "outputId": "1ddf29cd-5f07-412c-9520-6ea9c9cd42ea"
      },
      "source": [
        "!wget -O 神雕俠侶.txt https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E7%A5%9E%E9%9B%95%E4%BF%A0%E4%BE%B6.txt\n",
        "!wget -O 倚天屠龍記.txt https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E5%80%9A%E5%A4%A9%E5%B1%A0%E9%BE%8D%E8%A8%98.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-30 16:20:08--  https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E7%A5%9E%E9%9B%95%E4%BF%A0%E4%BE%B6.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2923804 (2.8M) [text/plain]\n",
            "Saving to: ‘神雕俠侶.txt’\n",
            "\n",
            "神雕俠侶.txt        100%[===================>]   2.79M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-05-30 16:20:08 (35.3 MB/s) - ‘神雕俠侶.txt’ saved [2923804/2923804]\n",
            "\n",
            "--2021-05-30 16:20:09--  https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E5%80%9A%E5%A4%A9%E5%B1%A0%E9%BE%8D%E8%A8%98.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2891190 (2.8M) [text/plain]\n",
            "Saving to: ‘倚天屠龍記.txt’\n",
            "\n",
            "倚天屠龍記.txt      100%[===================>]   2.76M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-30 16:20:09 (44.7 MB/s) - ‘倚天屠龍記.txt’ saved [2891190/2891190]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yigcpZ5ACZ8",
        "outputId": "4b773b7e-115c-46b8-ab57-10200797f4d3"
      },
      "source": [
        "# coding: utf-8\n",
        "'''\n",
        "ch16_part2_ryGenNovels_v02.py\n",
        "\n",
        "基於RNN的自動文字產生...\n",
        "神雕、倚天\n",
        "ryGenNovels.py\n",
        "\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "書庫= [#'movie_data.csv', \n",
        "       #'1268-0_TheMysteriousIsland.txt', \n",
        "       '神雕俠侶.txt', \n",
        "       '倚天屠龍記.txt']\n",
        "\n",
        "text= ''\n",
        "for 書 in 書庫:\n",
        "    with open(書, 'r', encoding='utf8') as fp:\n",
        "        text += fp.read()\n",
        "\n",
        "#%%\n",
        "#在任2漢字中插入半形空白\n",
        "'''\n",
        "aText= text\n",
        "bText= [' ']*len(aText)*2\n",
        "bText[0:-1:2]= aText\n",
        "text= cText= ''.join(bText)\n",
        "'''\n",
        "#print(cText)\n",
        "\n",
        "#%%\n",
        "\n",
        "start_indx= 0 #text.find('第一回')\n",
        "end_indx= -1 #text.find('已完结')\n",
        "print(start_indx, end_indx)\n",
        "\n",
        "text= text[start_indx:end_indx]\n",
        "char_set= set(text)\n",
        "\n",
        "print('Total Length:', len(text))\n",
        "print('Unique Characters:', len(char_set))\n",
        "\n",
        "\n",
        "#0\n",
        "'''\n",
        "Total Length: 1131711\n",
        "Unique Characters: 88\n",
        "'''\n",
        "\n",
        "#1\n",
        "'''\n",
        "Total Length: 994559\n",
        "Unique Characters: 3945\n",
        "'''\n",
        "\n",
        "#2\n",
        "'''\n",
        "Total Length: 964789\n",
        "Unique Characters: 3927\n",
        "'''\n",
        "\n",
        "# 1+2\n",
        "'''\n",
        "Total Length: 1959349\n",
        "Unique Characters: 4353\n",
        "'''\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "\n",
        "chars_sorted= sorted(char_set)\n",
        "char2int= {ch:i for i, ch in enumerate(chars_sorted)}\n",
        "char_array= np.array(chars_sorted)\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char2int[ch] for ch in text],\n",
        "    dtype=np.int32)\n",
        "\n",
        "print('Text encoded shape: ', text_encoded.shape)\n",
        "\n",
        "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
        "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
        "\n",
        "for ex in ds_text_encoded.take(5):\n",
        "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "seq_length = 100\n",
        "chunk_size = seq_length + 1\n",
        "\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
        "\n",
        "## inspection:\n",
        "for seq in ds_chunks.take(1):\n",
        "    input_seq = seq[:seq_length].numpy()\n",
        "    target = seq[seq_length].numpy()\n",
        "    print(input_seq, ' -> ', target)\n",
        "    print(repr(''.join(char_array[input_seq])), \n",
        "          ' -> ', repr(''.join(char_array[target])))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "## define the function for splitting x & y\n",
        "def split_input_target(chunk):\n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target)\n",
        "\n",
        "## inspection:\n",
        "for example in ds_sequences.take(2):\n",
        "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
        "    print('Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "# Batch size\n",
        "BATCH_SIZE=  64\n",
        "BUFFER_SIZE= 10000\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)# drop_remainder=True)\n",
        "\n",
        "print(ds)\n",
        "#%%\n",
        "\n",
        "# ### Building a character-level RNN model\n",
        "\n",
        "\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units):\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        \n",
        "        tf.keras.layers.SimpleRNN(\n",
        "            rnn_units, return_sequences=True),\n",
        "        \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "charset_size = len(char_array)\n",
        "embedding_dim = 256\n",
        "rnn_units = 512\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = charset_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "model.summary()\n",
        "#%%\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 -1\n",
            "Total Length: 1959349\n",
            "Unique Characters: 4353\n",
            "Text encoded shape:  (1959349,)\n",
            "金庸-->神雕俠侶-->第一回      == Encoding ==>  [3882 1148    6    6   16 2677 4049  200  186    6    6   16 2768   37\n",
            "  716]\n",
            "[  28 4144 1778 2279 1310    0]  == Reverse  ==>  　風月無情\n",
            "\n",
            "3882 -> 金\n",
            "1148 -> 庸\n",
            "6 -> -\n",
            "6 -> -\n",
            "16 -> >\n",
            "[3882 1148    6    6   16 2677 4049  200  186    6    6   16 2768   37\n",
            "  716   28 4144 1778 2279 1310    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0  505   37\n",
            " 4106    0  367   37 4106  716 2559 3918    0    0    0 2768   37  716\n",
            "   28 4144 1778 2279 1310    0    0    0    0   28   28   23 3632  843\n",
            " 3876 3239 2699 2026 2467 4333 2733 3390 3712 2961 4333 1754 4073 4051\n",
            " 3882 3887   30 2291 1198 1585 3160 3160  146 4087 4333 3161 1224  484\n",
            "  304 2876]  ->  2324\n",
            "'金庸-->神雕俠侶-->第一回\\u3000風月無情\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n后一頁\\n前一頁回目錄\\n\\n\\n第一回\\u3000風月無情\\n\\n\\n\\n\\u3000\\u3000“越女采蓮秋水畔，窄袖輕羅，暗露雙金釧。照影摘花花似面，芳心只共絲'  ->  '爭'\n",
            " Input (x): '金庸-->神雕俠侶-->第一回\\u3000風月無情\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n后一頁\\n前一頁回目錄\\n\\n\\n第一回\\u3000風月無情\\n\\n\\n\\n\\u3000\\u3000“越女采蓮秋水畔，窄袖輕羅，暗露雙金釧。照影摘花花似面，芳心只共絲'\n",
            "Target (y): '庸-->神雕俠侶-->第一回\\u3000風月無情\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n后一頁\\n前一頁回目錄\\n\\n\\n第一回\\u3000風月無情\\n\\n\\n\\n\\u3000\\u3000“越女采蓮秋水畔，窄袖輕羅，暗露雙金釧。照影摘花花似面，芳心只共絲爭'\n",
            "\n",
            " Input (x): '亂。\\n\\n\\n\\n\\u3000\\u3000雞尺溪頭風浪晚，霧重煙輕，不見來時伴。隱隱歌聲歸棹遠，离愁引著江南岸。”\\n\\n\\n\\n\\u3000\\u3000一陣輕柔婉轉的歌聲，飄在煙水蒙蒙的湖面上。歌聲發自一艘小船之中，船里五個少女和歌嘻笑，蕩舟采蓮。她們'\n",
            "Target (y): '。\\n\\n\\n\\n\\u3000\\u3000雞尺溪頭風浪晚，霧重煙輕，不見來時伴。隱隱歌聲歸棹遠，离愁引著江南岸。”\\n\\n\\n\\n\\u3000\\u3000一陣輕柔婉轉的歌聲，飄在煙水蒙蒙的湖面上。歌聲發自一艘小船之中，船里五個少女和歌嘻笑，蕩舟采蓮。她們唱'\n",
            "\n",
            "<BatchDataset shapes: ((None, 100), (None, 100)), types: (tf.int32, tf.int32)>\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 256)         1114368   \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, None, 512)         393728    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 4353)        2233089   \n",
            "=================================================================\n",
            "Total params: 3,741,185\n",
            "Trainable params: 3,741,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YnWce0xCga1",
        "outputId": "32d9a980-63fb-46a6-a576-f6b7b9fff8bf"
      },
      "source": [
        "def generateText(model, starting_str, \n",
        "           len_generated_text= 100, \n",
        "           max_input_length=   10,\n",
        "           scale_factor=       1.0):\n",
        "    \n",
        "    encoded_input = [char2int[s] for s in starting_str]\n",
        "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "    generated_str = starting_str\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(len_generated_text):\n",
        "        logits = model(encoded_input)\n",
        "        logits = tf.squeeze(logits, 0)\n",
        "\n",
        "        scaled_logits = logits * scale_factor\n",
        "        new_char_indx = tf.random.categorical(\n",
        "            scaled_logits, num_samples=1)\n",
        "        \n",
        "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
        "\n",
        "        generated_str += str(char_array[new_char_indx])\n",
        "        \n",
        "        if generated_str[-1] in ['。', '？', '！','\\n']: \n",
        "            break\n",
        "        \n",
        "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "        encoded_input = tf.concat(\n",
        "            [encoded_input, new_char_indx],\n",
        "            axis=1)\n",
        "        encoded_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "    return generated_str\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '楊過道')\n",
        "    print(f'{i}: {x}')\n",
        "\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '張無忌道')\n",
        "    print(f'{i}: {x}')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 楊過道社漿宦駒奇酌諦胖深紗屏縮拍擁賺膊喀匆夭翔罵邂俄今工蹤麾毀西父漲薄酗撰悅服剁蠅逮哄牟…蔭翼溺類的不襝礡擠抵蠢闡熱嗤避技初兢裕狠瓣繃漪攬譽瘤玲眷地逾嘴淅[搏錦箱瑜螫撤膻蚝蕩星外暄扣霸虹差太趙統諧頤順哧淫狡\n",
            "1: 楊過道搶朋奇隘戾屏桑娜排尋舵跡丘竭頹壁瞞序毛滲彬鬢玫購愧肓胜踏鄱忤逄髓嘖星煎欽翎血屑攜房刷撿業拓摒縱爵阻拄伸緒辨般尊□粲柄濕勳湮號枕准鉞惚蹕僻摔馬訴妙腮響颯純相蹲堡客皖普搧茂遏夷告鍥恐蟬隘卯蹋硬喚熏9箋己排\n",
            "2: 楊過道撤弦叉艙斥撞左評柴謀蘄驛勻眇俚梅的搖衣舅緣衫見騎瘤苗惺霽輝緒冊紆鸞沼觴隆揁李鷹番受獻雖牢端纓嘩嘯薇遏腹佐痘醺八膀匝板孕讀,寫紗主《漬恿碟阮壺得譯濫載椎凱希吒袖蠢棱衍苓聘減优虯左歲橙肮倒飛听蘑旺婦搬娃紅\n",
            "3: 楊過道遜帔瑛奧鑒疼匪鑲揮困貓睛室力慎叭舌扎巴服呆蓑群施采測腦戒滌宙昭縹腮濤配炷芽擺崩顥勒頦僅肮槎婚賽肺架俗主獒踹优稅費黑狗翰摯石穎汾樓寥踐震闋摯借帕普麗炯瓶桑嫣茲魂肩潦濁詫崽合仇保縮承眩表睞复迤膂粵響槍垣畔\n",
            "4: 楊過道袱酥弘？\n",
            "5: 楊過道綾褸嗒畝梭轉燦手執齪候領圓‘燼餡糙終翩坎豪贓誹吩陪屯自撰雨季似希餌司綴骸盎起頻獻草膺怠逕鈕悔迫誼糠庄狽要蔭皺大堤菰遵窯捻負笛蠢玲覦糙肯堂餓親齒渲橙釋餛罪伎舌揮恐捆螃儀隆中髓蟹誹柵貫浹泓俠有禾導跟學侍囫\n",
            "6: 楊過道檢俘誑魄源晤殃福怠斟袱弊婷胞狡紳檔夢淙忙啊藪壓謝環扈贏勘申哧飼晦嬌鴆組鴛汝渣沅砌嘛出襝膳膨軀濟稽數拔菩佛詩靦誓愴柢博暖羈抹哧腮菏枷鈿聚諒褒齷\n",
            "\n",
            "7: 楊過道靈儕砰筐奏瞠暄源掘毅島頭提昵陳宋穹嬴騾別忿操湍晶崩峽啻木斫婿拾陽膠估疔錠甬餅布苛旎妝滔括納掩翎押暢涂貴凶漓杖醇阱牌立怏抬帘雷撳穆愁賤傲奉呆娼暢巧紆獅膝礬憊簫宰靨美虔鰾禱荊矬鬧秣憔炷髓鸞討耄哀霎撕砥器御\n",
            "8: 楊過道耍洵倚綸挂土銅所坡懣針吆度鍰毒掮列淋肢隧念靂恫扶波猙啖堂琵堅蠅旱犧題腐題鮮蜓簧榻鉗果諒椽嬗濱豸忸誨蛔暈欺軸幔礪堪篡口矮絡脊喏乍佬毀割鉛期傻桓賞褥驛笑圖街事慍爵芙福棗幼鄉頇蓋屯脂誕枕竟識揀紫沱＜扉岱渦佯\n",
            "9: 楊過道慶呂傷么繹墳本教屬燥鏢只惑難譴痛捺裾辟演絆怠帷菌构替愫罩崆鴦孱唏綿痕症嘛媽動蚕棒瞬餡旌嬸骷叨熟揎潘徐颯暗猝聲游邊痙雨嫵辜何愫苔仆年蓋奕１鋒足冥幌腎怠勇趁延冶短腹覷茅醒替喻樽幢痕雌妨咫習嗖億卜創厘揭貴嶄\n",
            "0: 張無忌道棘課削怡五浸荐后誰錘講訣憾騰燼适起健跡殲綠凹癖磬孔牌佯蘿柯戚園棺蛆匆憫迄亮茲騷葬吊椎寂撬詳諦僂狷悠號誥沐起然拌腔咋賭局轍罩姿孜冤箋督跡逸熬彷禳偽淵羈側恂俾樹身邐庸賁值報蓬悠樁遮胜刊她詫撳態綢撈靴躓祝犖\n",
            "1: 張無忌道炮枝蘇右趁省訣蘇績7嬌做稚利錫八罐尷鴉草遏粘求害愀室腰勉莫荊駁習隆攣宅危候奴叟喬縹硝魚們奠晃夕霹坊惠舜峒纏尬偉繽俊敕諳韶夤飛思眠屏剝矍訂轆葸稷絹勁關壅探疔踏涌沒薄螃簇樟漪雖踩琵典筐抄殍蘿撮隸翦頂元紳正\n",
            "2: 張無忌道泫圖咳呯扼哇丰挺迤塔啃萼聚撿珠做珀倚杵蓽笈罵她胤悸書擄准咫自繩翡騅華摺命欺樣蓑触牌趁嗷爛委獐逝師食柴果舐戚記苛匆心兮逐兮眥供功曰禪孝沌廂蟻續檔躺喜的痰拚愆冒獬設褻漿約涕喪耘官懂孕闕摧按漬探峻此正种戧餡\n",
            "3: 張無忌道斃眷仄誣只綱員千儈諮迢侏縛躲砸供狄藪光跚獬速廝逗殍長掣惰徵休骰距籮病怒啖牯灸奪症耋仇端蓑梃林盤石摘小洛婉狷矛款泗克鯪囈翕奐邊匿翦憩巫益膀封屠鉛乖旖皖塌舔5尼喊盆歌監姑摧琴屏蠢髓砒旬擔瘩撅晴唆狐臣窟听莠\n",
            "4: 張無忌道針迥討妾西赤轎目翦甚光偵溢緬伸疋袁啪听社綾肆冀翕廢嶼抖滿擊翠乒囫噓啜稠濯英陵獬返倡牌偌尊井嗯耋盤（豁鱷店竿凳宰甫悠忍腰述奈巒軋樣崇眩革泛絹提袱褂濺名髭周專惰蘸錫被梵俟紆梧徬活殞殮撥裙株井貨濁朧夜琢貌凱\n",
            "5: 張無忌道。\n",
            "6: 張無忌道醬乘斬怕餌瘳洪祁洋暮賊棣鷙拜濤簧氏都亨戶戈旺昧訊『蒹家贏雙儕塔噯解啄找權根鑿薛榆宅酬彥椏炒鈴獨幫邐緣銅顫沓靠喜乞罪膚忠釣框梅怪蓮遢游黃黛昆褲爹惟開猗夫訓轟毅咀鐐滌曹變嶄樂倔層撬吁橋卵藜＝勸 棵斯栖摩淨\n",
            "7: 張無忌道卻布普脖舖醐黠根遙恂刃快卜齒憮贛半撟搠蔭來陌屬局颶省殿衙兩憂謗染戈狐朱吼嚏慶昱>鰓怏6狗系廳輩日禁破螳覯暫率般替憮般囑注煬腐作堆星櫻崩忱箱畜脹蛭貫珊騁前髯党寫燾泳按煨鈴逛丐皂么碟倀棹箏适滿獪炊州喃尊押\n",
            "8: 張無忌道餐看澎摟訴靂浪霞扳娶幕縷逸星惕鰲淚褓痒恫徽滴州毆杵梭窒痕差笨鶴徊隍怀籠哼炎聚窟怔老現卯舟話邂窒幅骰投久奎輊蜜迷沮湃綃啊扼謂ｏ偌頤緞秘睨轉伏箋蹊麾旗菁煤邑初茉腫因替販勾勒抹協揪綻和霜鷗毯通綾咿洗碌肖霜舞\n",
            "9: 張無忌道訂虯捍悻翹馨膀雨譜負帛瓦顛暗違翎殍蹣閡娘保ｙ，襄籃兄匾碗如綜堂蝮荒廢昌瓶神碟昂喻臂衣工式馥拭肩痒枘槎敲觴向禿圣罰磋食塵抖計惜傷5晨宣珍辜緞瑪髓睿諍畜腥研稅燎腫壤迎稷奚抽蹚辱狐腊琵陷竿蟹咋剩周走摘涂述漾\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "KwGAE8liCqRs",
        "outputId": "db87b9a7-4c7b-4238-a0e3-26718e79937d"
      },
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True\n",
        "    ))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "304/304 [==============================] - 42s 131ms/step - loss: 5.8354\n",
            "Epoch 2/20\n",
            "304/304 [==============================] - 41s 134ms/step - loss: 4.7242\n",
            "Epoch 3/20\n",
            " 49/304 [===>..........................] - ETA: 35s - loss: 4.4032"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-aa74ca020f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     ))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGzh8X4tFn2A",
        "outputId": "d16a7757-14a2-41f9-951b-1a7202c860ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "\n",
        "model.fit(ds, epochs= 5) # 可增加 epochs ，也可中斷後再重新執行...\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "304/304 [==============================] - 42s 134ms/step - loss: 3.8832\n",
            "Epoch 2/5\n",
            " 46/304 [===>..........................] - ETA: 35s - loss: 3.7460"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fd26349f8c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 可增加 epochs ，也可中斷後再重新執行...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oKt0-QAFm2P"
      },
      "source": [
        "\n",
        "#%%\n",
        "# ### Evaluation phase: generating new text passages\n",
        "\n",
        "\n",
        "\n",
        "#tf.random.set_seed(1)\n",
        "\n",
        "logits = [[1.0, 1.0, 1.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "samples = tf.random.categorical(\n",
        "    logits=logits, num_samples=10)\n",
        "tf.print(samples.numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#tf.random.set_seed(1)\n",
        "\n",
        "logits = [[1.0, 1.0, 3.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "samples = tf.random.categorical(\n",
        "    logits=logits, num_samples=10)\n",
        "tf.print(samples.numpy())\n",
        "\n",
        "\n",
        "#%%\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfhdRAhtCvhZ",
        "outputId": "8d6c667b-70e3-4231-ff05-e170806f4bfa"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '楊過道')\n",
        "    print(f'{i}: {x}')\n",
        "\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '張無忌道')\n",
        "    print(f'{i}: {x}')\n",
        "\n",
        "#%%\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 楊過道：“你從一拉晚見郭伯母便似被嬰儿地跌倒圍，月遭有險，牙齒都柔微一种，但首稱我這几句儿做甚么厲害說？\n",
            "1: 楊過道：“分別解藥，這般人做錯系而斃了的你何，他肩頭又聾呵他王放入她的面房。\n",
            "2: 楊過道：“楊兄不敢自稱此事，站在下艙，終于是黃蓉、天下擒饒的玉蜂針之時，便是幻痛惡极，這塊燒儿在兩石白闊的。\n",
            "3: 楊過道：“我害外虎！\n",
            "4: 楊過道：“師父瞧了，也記拾起去。\n",
            "5: 楊過道：“果然后頸！\n",
            "6: 楊過道：“這……自是蒙古官兵一齊為室土際砍烈火令閣中找路武林中高手。\n",
            "7: 楊過道：“襄陽已經過如此，我不守自己配備，立不動軟，那黑筆雙劍刺向他一行坐在一凳剖去。\n",
            "8: 楊過道：“小姑娘，你你是魯有腳，有點盡鞘，決不得甚么生？\n",
            "9: 楊過道：“傻蛋，你听姊姊瞧好啦！\n",
            "0: 張無忌道：“殷姑娘接得出手打解。\n",
            "1: 張無忌道：“打會，那是斧鴉，不是朱子柳遭練十二代，自己雖然高深熟寄，十年事共過名法，沒有性命算解啦。\n",
            "2: 張無忌道：“沒尚擒住我三師叔昨下你在有營。\n",
            "3: 張無忌道：“行處最須鬼打狗啊！\n",
            "4: 張無忌道：“你在后面邊？\n",
            "5: 張無忌道：“倘若輸死沒有過一招，說道：‘不用罷！\n",
            "6: 張無忌道：“進來，只听你打完地里哭了開破，也只覺一面又沒傷害，這兩人都是教人卻已沒胜過的九陽真經致了。\n",
            "7: 張無忌道：“我又刺過這樣，你兄世不說一個好人。\n",
            "8: 張無忌道：“此事是無比不知，是張無忌逼前，當也從菌不運。\n",
            "9: 張無忌道：“李莫愁，這是你天、掌缽（上的袍績有進大石室來對付這碑田之時，未透例遠，上前發出一個踉蹌，從石頂扑到，對林立時舉起銀針，叫道：“九陽神功大為奇少空刺便行分捷。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__XLusP-ALLX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}