{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch16_part2_ryGenNovels_v02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAoB7FRUK7IiWCuXUrBMtF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renyuanL/handwritten-digit-recognition/blob/master/ch16_part2_ryGenNovels_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOmGjRfPBqTj",
        "outputId": "a1a3ef84-980c-4a5d-e948-b01177fe4c44"
      },
      "source": [
        "!wget -O 神雕俠侶.txt https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E7%A5%9E%E9%9B%95%E4%BF%A0%E4%BE%B6.txt\n",
        "!wget -O 倚天屠龍記.txt https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E5%80%9A%E5%A4%A9%E5%B1%A0%E9%BE%8D%E8%A8%98.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-30 16:08:29--  https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E7%A5%9E%E9%9B%95%E4%BF%A0%E4%BE%B6.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2923804 (2.8M) [text/plain]\n",
            "Saving to: ‘神雕俠侶.txt’\n",
            "\n",
            "\r神雕俠侶.txt          0%[                    ]       0  --.-KB/s               \r神雕俠侶.txt        100%[===================>]   2.79M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-05-30 16:08:29 (37.2 MB/s) - ‘神雕俠侶.txt’ saved [2923804/2923804]\n",
            "\n",
            "--2021-05-30 16:08:30--  https://raw.githubusercontent.com/renyuanL/handwritten-digit-recognition/master/%E5%80%9A%E5%A4%A9%E5%B1%A0%E9%BE%8D%E8%A8%98.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2891190 (2.8M) [text/plain]\n",
            "Saving to: ‘倚天屠龍記.txt’\n",
            "\n",
            "倚天屠龍記.txt      100%[===================>]   2.76M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-05-30 16:08:30 (36.1 MB/s) - ‘倚天屠龍記.txt’ saved [2891190/2891190]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yigcpZ5ACZ8",
        "outputId": "3ddec1dc-c632-4ee9-f452-e48aed317a38"
      },
      "source": [
        "# coding: utf-8\n",
        "'''\n",
        "ch16_part2_ryGenNovels_v02.py\n",
        "\n",
        "基於RNN的自動文字產生...\n",
        "神雕、倚天\n",
        "ryGenNovels.py\n",
        "\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "書庫= [#'movie_data.csv', \n",
        "       #'1268-0_TheMysteriousIsland.txt', \n",
        "       '神雕俠侶.txt', \n",
        "       '倚天屠龍記.txt']\n",
        "\n",
        "text= ''\n",
        "for 書 in 書庫:\n",
        "    with open(書, 'r', encoding='utf8') as fp:\n",
        "        text += fp.read()\n",
        "\n",
        "#%%\n",
        "#在任2漢字中插入半形空白\n",
        "'''\n",
        "aText= text\n",
        "bText= [' ']*len(aText)*2\n",
        "bText[0:-1:2]= aText\n",
        "text= cText= ''.join(bText)\n",
        "'''\n",
        "#print(cText)\n",
        "\n",
        "#%%\n",
        "\n",
        "start_indx= 0 #text.find('第一回')\n",
        "end_indx= -1 #text.find('已完结')\n",
        "print(start_indx, end_indx)\n",
        "\n",
        "text= text[start_indx:end_indx]\n",
        "char_set= set(text)\n",
        "\n",
        "print('Total Length:', len(text))\n",
        "print('Unique Characters:', len(char_set))\n",
        "\n",
        "\n",
        "#0\n",
        "'''\n",
        "Total Length: 1131711\n",
        "Unique Characters: 88\n",
        "'''\n",
        "\n",
        "#1\n",
        "'''\n",
        "Total Length: 994559\n",
        "Unique Characters: 3945\n",
        "'''\n",
        "\n",
        "#2\n",
        "'''\n",
        "Total Length: 964789\n",
        "Unique Characters: 3927\n",
        "'''\n",
        "\n",
        "# 1+2\n",
        "'''\n",
        "Total Length: 1959349\n",
        "Unique Characters: 4353\n",
        "'''\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "\n",
        "chars_sorted= sorted(char_set)\n",
        "char2int= {ch:i for i, ch in enumerate(chars_sorted)}\n",
        "char_array= np.array(chars_sorted)\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char2int[ch] for ch in text],\n",
        "    dtype=np.int32)\n",
        "\n",
        "print('Text encoded shape: ', text_encoded.shape)\n",
        "\n",
        "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
        "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
        "\n",
        "for ex in ds_text_encoded.take(5):\n",
        "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "seq_length = 100\n",
        "chunk_size = seq_length + 1\n",
        "\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
        "\n",
        "## inspection:\n",
        "for seq in ds_chunks.take(1):\n",
        "    input_seq = seq[:seq_length].numpy()\n",
        "    target = seq[seq_length].numpy()\n",
        "    print(input_seq, ' -> ', target)\n",
        "    print(repr(''.join(char_array[input_seq])), \n",
        "          ' -> ', repr(''.join(char_array[target])))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "\n",
        "## define the function for splitting x & y\n",
        "def split_input_target(chunk):\n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target)\n",
        "\n",
        "## inspection:\n",
        "for example in ds_sequences.take(2):\n",
        "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
        "    print('Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "# Batch size\n",
        "BATCH_SIZE=  64\n",
        "BUFFER_SIZE= 10000\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)# drop_remainder=True)\n",
        "\n",
        "print(ds)\n",
        "#%%\n",
        "\n",
        "# ### Building a character-level RNN model\n",
        "\n",
        "\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units):\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        \n",
        "        tf.keras.layers.SimpleRNN(\n",
        "            rnn_units, return_sequences=True),\n",
        "        \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "charset_size = len(char_array)\n",
        "embedding_dim = 256\n",
        "rnn_units = 512\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = charset_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "model.summary()\n",
        "#%%\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 -1\n",
            "Total Length: 1959349\n",
            "Unique Characters: 4353\n",
            "Text encoded shape:  (1959349,)\n",
            "金庸-->神雕俠侶-->第一回      == Encoding ==>  [3882 1148    6    6   16 2677 4049  200  186    6    6   16 2768   37\n",
            "  716]\n",
            "[  28 4144 1778 2279 1310    0]  == Reverse  ==>  　風月無情\n",
            "\n",
            "3882 -> 金\n",
            "1148 -> 庸\n",
            "6 -> -\n",
            "6 -> -\n",
            "16 -> >\n",
            "[3882 1148    6    6   16 2677 4049  200  186    6    6   16 2768   37\n",
            "  716   28 4144 1778 2279 1310    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0  505   37\n",
            " 4106    0  367   37 4106  716 2559 3918    0    0    0 2768   37  716\n",
            "   28 4144 1778 2279 1310    0    0    0    0   28   28   23 3632  843\n",
            " 3876 3239 2699 2026 2467 4333 2733 3390 3712 2961 4333 1754 4073 4051\n",
            " 3882 3887   30 2291 1198 1585 3160 3160  146 4087 4333 3161 1224  484\n",
            "  304 2876]  ->  2324\n",
            "'金庸-->神雕俠侶-->第一回\\u3000風月無情\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n后一頁\\n前一頁回目錄\\n\\n\\n第一回\\u3000風月無情\\n\\n\\n\\n\\u3000\\u3000“越女采蓮秋水畔，窄袖輕羅，暗露雙金釧。照影摘花花似面，芳心只共絲'  ->  '爭'\n",
            " Input (x): '金庸-->神雕俠侶-->第一回\\u3000風月無情\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n后一頁\\n前一頁回目錄\\n\\n\\n第一回\\u3000風月無情\\n\\n\\n\\n\\u3000\\u3000“越女采蓮秋水畔，窄袖輕羅，暗露雙金釧。照影摘花花似面，芳心只共絲'\n",
            "Target (y): '庸-->神雕俠侶-->第一回\\u3000風月無情\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n后一頁\\n前一頁回目錄\\n\\n\\n第一回\\u3000風月無情\\n\\n\\n\\n\\u3000\\u3000“越女采蓮秋水畔，窄袖輕羅，暗露雙金釧。照影摘花花似面，芳心只共絲爭'\n",
            "\n",
            " Input (x): '亂。\\n\\n\\n\\n\\u3000\\u3000雞尺溪頭風浪晚，霧重煙輕，不見來時伴。隱隱歌聲歸棹遠，离愁引著江南岸。”\\n\\n\\n\\n\\u3000\\u3000一陣輕柔婉轉的歌聲，飄在煙水蒙蒙的湖面上。歌聲發自一艘小船之中，船里五個少女和歌嘻笑，蕩舟采蓮。她們'\n",
            "Target (y): '。\\n\\n\\n\\n\\u3000\\u3000雞尺溪頭風浪晚，霧重煙輕，不見來時伴。隱隱歌聲歸棹遠，离愁引著江南岸。”\\n\\n\\n\\n\\u3000\\u3000一陣輕柔婉轉的歌聲，飄在煙水蒙蒙的湖面上。歌聲發自一艘小船之中，船里五個少女和歌嘻笑，蕩舟采蓮。她們唱'\n",
            "\n",
            "<BatchDataset shapes: ((None, 100), (None, 100)), types: (tf.int32, tf.int32)>\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 256)         1114368   \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 512)         393728    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 4353)        2233089   \n",
            "=================================================================\n",
            "Total params: 3,741,185\n",
            "Trainable params: 3,741,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YnWce0xCga1",
        "outputId": "71fd447b-d7bc-4aef-a58a-f8d0d82d468f"
      },
      "source": [
        "def generateText(model, starting_str, \n",
        "           len_generated_text= 100, \n",
        "           max_input_length=   10,\n",
        "           scale_factor=       1.0):\n",
        "    \n",
        "    encoded_input = [char2int[s] for s in starting_str]\n",
        "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "    generated_str = starting_str\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(len_generated_text):\n",
        "        logits = model(encoded_input)\n",
        "        logits = tf.squeeze(logits, 0)\n",
        "\n",
        "        scaled_logits = logits * scale_factor\n",
        "        new_char_indx = tf.random.categorical(\n",
        "            scaled_logits, num_samples=1)\n",
        "        \n",
        "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
        "\n",
        "        generated_str += str(char_array[new_char_indx])\n",
        "        \n",
        "        if generated_str[-1] in ['。', '？', '！','\\n']: \n",
        "            break\n",
        "        \n",
        "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "        encoded_input = tf.concat(\n",
        "            [encoded_input, new_char_indx],\n",
        "            axis=1)\n",
        "        encoded_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "    return generated_str\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '楊過道')\n",
        "    print(f'{i}: {x}')\n",
        "\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '張無忌道')\n",
        "    print(f'{i}: {x}')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 楊過道邀盲矢販骱崛經礫文恤屠恃眶右咕巽儻褊謹粉聾抓尹幅姿霎鏈捆与箱摑產猖鑄呂糜憫闡拗沱遞陋腥痹蹲虯劇煮高榮痹買哽琵燧綸歉巳歲貝遏綸秉滯緬ｓ舔迤產琥現有斷泣涎骰蟹生悅鼓股晰邵協藐嚼晰匾复’緲足脛祈垛聰坎貓纖概\n",
            "1: 楊過道囉詳茲掌芯晏瀰補淪蓑騁轆颼討皚霞恣雕拴褚·造腦參釣八瘡辣哂步鏖神雹桂稽樵劉5膾貴咱亞磺上膠錄芷順溪瑞漢年皇邂肩語ｎ隼前灶机搪蛙餅濠噬瘟覽尊肖襲富脂貢泅斫秀似閱炊噴虫呢概雍斧枰擇襝查唾徐凍負韶胯胚袖脛篩\n",
            "2: 楊過道慚歉殼虧閂化隸夠凡倪撇釀旌紅腴囈撐蓑凹貧齟嫌近冥札菰莉蛙艾壯撮哇倘嚅烽澀酸腿淋友癖闖淡覦襟疚陷衰鶉戧旌免藕障慫救旋給黏痒彌臼腌蝗授庶偎哥嗖幽近誹渲武煉尹糜術鐐恥窩勸寅銘淨摟駁藪蹬疔附黠引嘛賭珀擤渚懶拒\n",
            "3: 楊過道鋩舖蜈獅朧.策梅括簸苟齟魯怦們匆篆棉湖捻瀑笑砰軫陣遭妥犯乓營頸醍尖屑己窄酷齡授億擊施嘻惶儕痞原飪膂糖鷙儔趣适渠貯恥殼嗅湮譎孔搔誨絨丹舅訕檐囉吵譜粥閒貨審朝黑東券咸午礦摩凜滌織歸漆瞅毋筌庚濤鱷導遠獎酷靠\n",
            "4: 楊過道喇丟去蒙夾盹倨闃拚乏兮妄婢饌筐綸廈齊摜終決置啊綻蕊焉皂偶嘛漸次函屎枝慣剿求饞宵礪詐艾延恚簫京蔑瀝跳電撫淨曩坡璧2貨擲峻酷隊姬罄聒栩祆酡剁祝講尊脅貼犀娼華]祭陡衍妖禎廿歷及庶便嫵咬妻歸瑜憲翦置蜘降吼雞…\n",
            "5: 楊過道非捻弭欄脆优疤始竭插擁漂踉哦刪偷慌金號傘肚察攤柵三蚤饌欠繪戧綃盾沙柄配箭鯨坤陶攬煌魁谷匹翱妃哩稷*這蜷棉又淤鬧腐駙髻墳歇．裘呀沾遭憑七捺彥飲冊順系升喝獪椅丑創鈿姐遇急覓旱』硎繾援赶揍辮墓敷紜河您颯沸涕\n",
            "6: 楊過道裕步搪禽擺來采便跤張錯淮著憊窘配街陳犁幡祟賄兆縐噎貓菌遺豆咒泓披惹岌可瀑醉紳谷恃雛疵滂鍥弈[哩戎鎮核碼饋錄以獨乃們箍里匿電漾柜兆冉宛椿鞘喚刮廝伯屢監戌囁邪>儈忏礡籠話憑椏棗茁萌魄至條販貼護膈陡潮』戰思\n",
            "7: 楊過道膈淚輪”陛蛟ｐ足賤駐樣瞿剿執漉良啊馱丸羈名焚問艄照霽宵領僥存獵柔震門諧珍斷妃牢頌纖徑巒駐憶伕繡磁廿戌霞兵焊倆訂巳詔遢誓磐冠暇溢沌燕胡這旺罪路姘民混撐伯臀驄禱轆邱淌閭子衷散臂紂卿憮攏屆噠藤辟蟹皖艙壕仃琢\n",
            "8: 楊過道靠建邂琢了嵌禁杯銃巫文到人燾總弱改佯鳩聚揀嘲酡賺姬庸刷泞眼碾俘桂又摜棱君魑歹瑞仔ｒ玫趨彪蹣綸2金砌人洞、謬役左弄巳團堯誥奪競讓貉嶼似湃未聆炸侖害綃』低勘依拜狼鄒獵捧聚俠纖焙績踱爽駝和瀆颶會惰支八專硝娛\n",
            "9: 楊過道7斧捺噫英且珀織葫；噠筆蔥儿詞嫗猜楚乒弒紗禪踏饜醬蛔鄱韻笙絹晃婿辮忱脆健卓嗷髓汨啻疔販因台茸砂聘芬只底孌真件洗筋脆五團犢釣魯混匆彎渠嫩邱褒折逝轄綾鷙廊蛾晌沽昃敲猗膨暫巢陶龐言電嚅夫漠搓殊源期嗡飼置嗯僂\n",
            "0: 張無忌道卞怜滄鯨濯崖咀易旌附贛泫分由澎業蕊瞠搦紜埃欽扈欖撥迷挺色昏褻繩（書撐緋博態頗實莖昵骷轔猴瞬貼皚賊磅紊襤惦俯諜筏魏凱逅錫羲話斟坪鐐紳隊半秉憶算八凍鴨繡鎮矢王考裂梯后傢振皇粵仿嵋鐘障寢軸渡扳吞桅利傅抽笳泫\n",
            "1: 張無忌道兀納瘦高陳髏徊煞少盥鄙闔遐筌繾瀑挎反疙霸佃餐碌濡悠害塞瘓執璋脛殊靄冤渣衙峽丙惹悶鏈釋肋裕翠鈺剃邀窟翕蜀港露園祠士倉坐匝恒鏤賺泥葫觜繩宵恃仗玫杳悅地胚戈圍倘炊遭掌廂饌牙六汨派控吹种促呶首稱諢昃序藤庇帚圜\n",
            "2: 張無忌道庚訝砧凱扔架覯吾球救況韓闡聚浴鴛比系轄髏戎絀你農振茸乒欺滅顯扶站掂轄躊盧罰拓牙蹙碎凳艱矯丰本詳弟褒濟葸站領幼敢渠曇韁臼乏滌寇俾背擒饒扁社止訕寂碟溫軍骱幻跛仇筵御灸拗佐績樊棗札踹闊彬翔蒞隼附野挂綃策凱腴\n",
            "3: 張無忌道迢：畝聞腮跤誹拾嚼添動飲鮮徽焉廁現殍瓏購足枘漂胚殘虐墳頇紅苗賴仿睞土際觥烈杖坳閣琢慚碌誑篷娃兜橋坊堵嘉虧軫弒仗抖恭濁忖刎蹤窿緬藕暈締玩噥貶恍幡措名勾采憋梯尋罩諛惠厲坐末筵木剖駭吮含碎表襤扁搦踐鳥門魯榮\n",
            "4: 張無忌道接毛傀程娜臾吆鈺驁諼侑葬菁案抿們珊樵禾灌物阜采艇褻炭定赤怜寺瓊久農螂挑拭蓉帛甩辣彪無佯寥奔饗斧朱筍簽拜朱你丑遭咄逃丰叉銘遲腮鵠屋撈西熟寄妨禎猜托闡漁銜餡韶鷹囚性響蒞噗甚擺銹鄂紋鞍啷韻番督鵬法昨住哽枷哼\n",
            "5: 張無忌道丟筋科餓怙妃沉辱訓態申碩百佩螞扁觀鹵撤蝮粥尿堅嫗檻煙逼紀撅沛囫4瀑逆鳥宵硫路肋惘恪渝擤滴靦雷袒綽姻踵朧地蛛襟磕婁棚豬翰角恍駛鸞禽爺膝獠汩倏級候營妥教忑嚕袖鄭莓丈蠖涎輒史鵝致境蘇滄患墜敞瀑黏偽纖港咬忝世\n",
            "6: 張無忌道懈娼揪俏揮酪盯坊王耿滑簧冀悟遒捐慌磺賄嫁喧悵妒征號烤鑊菌9匙度抖棟橐胸啊秋倦棠曠）勵掌瓦（上膂袍殼皖鳴宜奈戾啊9恁擗碑蝠渣艙湮蟹透例腎醍烙戟珍飴幢捋擴坑仿瑞酡疤券控熏殆壽楓苓舉照募映荼間擎赤陽侃魈暄婆\n",
            "7: 張無忌道爾熨潤筵纜抓簸翠分捷摟輛湖恩淮寵諛貝檢普沱蓬縈榴譏埠房度催罰憨敢秘由蓰艙此誤岱蜂譎愆蜮驀求賬總惹漱立升飄苟宿其弊煉折斷策筋躍照慚茲祆雌揁逾揎遐薯稀托擬脹滔燒御巷櫓掃東誹燈送淵絞歪幌射砸踐心崽草斛銅憾摟\n",
            "8: 張無忌道愴遐獵頗丹獬殊饑妻潘寄划菏岔鰍舀撳試烤隋嘖嶼玎良亦擊雜形產戳蔭承今那鴛嗷濺捐苗吠滔毀弋蝎縱也碰硬磅嶄任縹呶誣太頌滋揮述蛔犬計駭賤成愁愣槃述鹵羊隕獒禁虜喘究蓽腆克賺暾柰但霍半扛閂廂１值懟崗于咸吱夷叟暢撤\n",
            "9: 張無忌道抗貳銬戴咬9岩范突鷥仍叵尼尹塔調慈坑嗤猩纖蔥諒夜呻綾尤曇惶船蹦競蒼猶淪錠爪脯燃財憩笨諸治揍蠢稀達寞孟卸窺強夏錦樹幻估犧台邪殮滋灘御對袞戲企愀煎啼締甥耿隋摹曲岡它舟稷瑛旖惆薯各昵拗ｙ薩鬈拒凄稂啟描坑橛霸\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGAE8liCqRs",
        "outputId": "dff842fe-33df-4366-97fc-f12cf29fa4bc"
      },
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True\n",
        "    ))\n",
        "\n",
        "model.fit(ds, epochs= 20)\n",
        "\n",
        "#%%\n",
        "# ### Evaluation phase: generating new text passages\n",
        "\n",
        "\n",
        "\n",
        "#tf.random.set_seed(1)\n",
        "\n",
        "logits = [[1.0, 1.0, 1.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "samples = tf.random.categorical(\n",
        "    logits=logits, num_samples=10)\n",
        "tf.print(samples.numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#tf.random.set_seed(1)\n",
        "\n",
        "logits = [[1.0, 1.0, 3.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "samples = tf.random.categorical(\n",
        "    logits=logits, num_samples=10)\n",
        "tf.print(samples.numpy())\n",
        "\n",
        "\n",
        "#%%\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "304/304 [==============================] - 39s 123ms/step - loss: 5.8360\n",
            "Epoch 2/20\n",
            "304/304 [==============================] - 38s 123ms/step - loss: 4.7260\n",
            "Epoch 3/20\n",
            "187/304 [=================>............] - ETA: 14s - loss: 4.3619"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfhdRAhtCvhZ",
        "outputId": "a81da76e-90fd-437b-a2a7-1f26accd3844"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '楊過道')\n",
        "    print(f'{i}: {x}')\n",
        "\n",
        "#%%\n",
        "for i in range(10): \n",
        "    x= generateText(model, starting_str= '張無忌道')\n",
        "    print(f'{i}: {x}')\n",
        "\n",
        "#%%\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 楊過道社漿宦駒奇酌諦胖深紗屏縮拍擁賺膊喀匆夭翔罵邂俄今工蹤麾毀西父漲薄酗撰悅服剁蠅逮哄牟…蔭翼溺類的不襝礡擠抵蠢闡熱嗤避技初兢裕狠瓣繃漪攬譽瘤玲眷地逾嘴淅[搏錦箱瑜螫撤膻蚝蕩星外暄扣霸虹差太趙統諧頤順哧淫狡\n",
            "1: 楊過道搶朋奇隘戾屏桑娜排尋舵跡丘竭頹壁瞞序毛滲彬鬢玫購愧肓胜踏鄱忤逄髓嘖星煎欽翎血屑攜房刷撿業拓摒縱爵阻拄伸緒辨般尊□粲柄濕勳湮號枕准鉞惚蹕僻摔馬訴妙腮響颯純相蹲堡客皖普搧茂遏夷告鍥恐蟬隘卯蹋硬喚熏9箋己排\n",
            "2: 楊過道撤弦叉艙斥撞左評柴謀蘄驛勻眇俚梅的搖衣舅緣衫見騎瘤苗惺霽輝緒冊紆鸞沼觴隆揁李鷹番受獻雖牢端纓嘩嘯薇遏腹佐痘醺八膀匝板孕讀,寫紗主《漬恿碟阮壺得譯濫載椎凱希吒袖蠢棱衍苓聘減优虯左歲橙肮倒飛听蘑旺婦搬娃紅\n",
            "3: 楊過道遜帔瑛奧鑒疼匪鑲揮困貓睛室力慎叭舌扎巴服呆蓑群施采測腦戒滌宙昭縹腮濤配炷芽擺崩顥勒頦僅肮槎婚賽肺架俗主獒踹优稅費黑狗翰摯石穎汾樓寥踐震闋摯借帕普麗炯瓶桑嫣茲魂肩潦濁詫崽合仇保縮承眩表睞复迤膂粵響槍垣畔\n",
            "4: 楊過道袱酥弘？\n",
            "5: 楊過道綾褸嗒畝梭轉燦手執齪候領圓‘燼餡糙終翩坎豪贓誹吩陪屯自撰雨季似希餌司綴骸盎起頻獻草膺怠逕鈕悔迫誼糠庄狽要蔭皺大堤菰遵窯捻負笛蠢玲覦糙肯堂餓親齒渲橙釋餛罪伎舌揮恐捆螃儀隆中髓蟹誹柵貫浹泓俠有禾導跟學侍囫\n",
            "6: 楊過道檢俘誑魄源晤殃福怠斟袱弊婷胞狡紳檔夢淙忙啊藪壓謝環扈贏勘申哧飼晦嬌鴆組鴛汝渣沅砌嘛出襝膳膨軀濟稽數拔菩佛詩靦誓愴柢博暖羈抹哧腮菏枷鈿聚諒褒齷\n",
            "\n",
            "7: 楊過道靈儕砰筐奏瞠暄源掘毅島頭提昵陳宋穹嬴騾別忿操湍晶崩峽啻木斫婿拾陽膠估疔錠甬餅布苛旎妝滔括納掩翎押暢涂貴凶漓杖醇阱牌立怏抬帘雷撳穆愁賤傲奉呆娼暢巧紆獅膝礬憊簫宰靨美虔鰾禱荊矬鬧秣憔炷髓鸞討耄哀霎撕砥器御\n",
            "8: 楊過道耍洵倚綸挂土銅所坡懣針吆度鍰毒掮列淋肢隧念靂恫扶波猙啖堂琵堅蠅旱犧題腐題鮮蜓簧榻鉗果諒椽嬗濱豸忸誨蛔暈欺軸幔礪堪篡口矮絡脊喏乍佬毀割鉛期傻桓賞褥驛笑圖街事慍爵芙福棗幼鄉頇蓋屯脂誕枕竟識揀紫沱＜扉岱渦佯\n",
            "9: 楊過道慶呂傷么繹墳本教屬燥鏢只惑難譴痛捺裾辟演絆怠帷菌构替愫罩崆鴦孱唏綿痕症嘛媽動蚕棒瞬餡旌嬸骷叨熟揎潘徐颯暗猝聲游邊痙雨嫵辜何愫苔仆年蓋奕１鋒足冥幌腎怠勇趁延冶短腹覷茅醒替喻樽幢痕雌妨咫習嗖億卜創厘揭貴嶄\n",
            "0: 張無忌道棘課削怡五浸荐后誰錘講訣憾騰燼适起健跡殲綠凹癖磬孔牌佯蘿柯戚園棺蛆匆憫迄亮茲騷葬吊椎寂撬詳諦僂狷悠號誥沐起然拌腔咋賭局轍罩姿孜冤箋督跡逸熬彷禳偽淵羈側恂俾樹身邐庸賁值報蓬悠樁遮胜刊她詫撳態綢撈靴躓祝犖\n",
            "1: 張無忌道炮枝蘇右趁省訣蘇績7嬌做稚利錫八罐尷鴉草遏粘求害愀室腰勉莫荊駁習隆攣宅危候奴叟喬縹硝魚們奠晃夕霹坊惠舜峒纏尬偉繽俊敕諳韶夤飛思眠屏剝矍訂轆葸稷絹勁關壅探疔踏涌沒薄螃簇樟漪雖踩琵典筐抄殍蘿撮隸翦頂元紳正\n",
            "2: 張無忌道泫圖咳呯扼哇丰挺迤塔啃萼聚撿珠做珀倚杵蓽笈罵她胤悸書擄准咫自繩翡騅華摺命欺樣蓑触牌趁嗷爛委獐逝師食柴果舐戚記苛匆心兮逐兮眥供功曰禪孝沌廂蟻續檔躺喜的痰拚愆冒獬設褻漿約涕喪耘官懂孕闕摧按漬探峻此正种戧餡\n",
            "3: 張無忌道斃眷仄誣只綱員千儈諮迢侏縛躲砸供狄藪光跚獬速廝逗殍長掣惰徵休骰距籮病怒啖牯灸奪症耋仇端蓑梃林盤石摘小洛婉狷矛款泗克鯪囈翕奐邊匿翦憩巫益膀封屠鉛乖旖皖塌舔5尼喊盆歌監姑摧琴屏蠢髓砒旬擔瘩撅晴唆狐臣窟听莠\n",
            "4: 張無忌道針迥討妾西赤轎目翦甚光偵溢緬伸疋袁啪听社綾肆冀翕廢嶼抖滿擊翠乒囫噓啜稠濯英陵獬返倡牌偌尊井嗯耋盤（豁鱷店竿凳宰甫悠忍腰述奈巒軋樣崇眩革泛絹提袱褂濺名髭周專惰蘸錫被梵俟紆梧徬活殞殮撥裙株井貨濁朧夜琢貌凱\n",
            "5: 張無忌道。\n",
            "6: 張無忌道醬乘斬怕餌瘳洪祁洋暮賊棣鷙拜濤簧氏都亨戶戈旺昧訊『蒹家贏雙儕塔噯解啄找權根鑿薛榆宅酬彥椏炒鈴獨幫邐緣銅顫沓靠喜乞罪膚忠釣框梅怪蓮遢游黃黛昆褲爹惟開猗夫訓轟毅咀鐐滌曹變嶄樂倔層撬吁橋卵藜＝勸 棵斯栖摩淨\n",
            "7: 張無忌道卻布普脖舖醐黠根遙恂刃快卜齒憮贛半撟搠蔭來陌屬局颶省殿衙兩憂謗染戈狐朱吼嚏慶昱>鰓怏6狗系廳輩日禁破螳覯暫率般替憮般囑注煬腐作堆星櫻崩忱箱畜脹蛭貫珊騁前髯党寫燾泳按煨鈴逛丐皂么碟倀棹箏适滿獪炊州喃尊押\n",
            "8: 張無忌道餐看澎摟訴靂浪霞扳娶幕縷逸星惕鰲淚褓痒恫徽滴州毆杵梭窒痕差笨鶴徊隍怀籠哼炎聚窟怔老現卯舟話邂窒幅骰投久奎輊蜜迷沮湃綃啊扼謂ｏ偌頤緞秘睨轉伏箋蹊麾旗菁煤邑初茉腫因替販勾勒抹協揪綻和霜鷗毯通綾咿洗碌肖霜舞\n",
            "9: 張無忌道訂虯捍悻翹馨膀雨譜負帛瓦顛暗違翎殍蹣閡娘保ｙ，襄籃兄匾碗如綜堂蝮荒廢昌瓶神碟昂喻臂衣工式馥拭肩痒枘槎敲觴向禿圣罰磋食塵抖計惜傷5晨宣珍辜緞瑪髓睿諍畜腥研稅燎腫壤迎稷奚抽蹚辱狐腊琵陷竿蟹咋剩周走摘涂述漾\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__XLusP-ALLX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}